{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is for data cleaning it focuses on field level and model level data \n",
    "It is also helpful for developers to clean the record using json plugin file\n",
    "It supports extensible and modular deisgn \n",
    "\n",
    "Framework Overview: the code cleans the records with the help of field(each record) and model(whole dataset) cleaner.\n",
    "\n",
    "\n",
    "Key Components:\n",
    "\n",
    "Cleaner Registry -> used to register field and model cleaner get the fields/models,get the params or keys. \n",
    "\n",
    "\n",
    "Cleaner Manager -> used to take the cleaning rules from the json file(plugins)\n",
    "\n",
    "\n",
    "Cleaner Config and Field Cleaner config -> defines config for single field\n",
    "\n",
    "\n",
    "ModelCleanerConfig -> defines config for multiple fileds or whole dataset at a time\n",
    "\n",
    "\n",
    "SchemaConfig -> used to define config for schema_name,field and model config as input\n",
    "\n",
    "Classes\n",
    "\n",
    "\n",
    "Fields: strips whitecase, converts to lowercase, fill na,type conversion, removes non numeric characters \n",
    "\n",
    "\n",
    "Models: drop duplicates, outlier treatment \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Any, Callable, Dict, List, Optional\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from pydantic import BaseModel, PrivateAttr, create_model, ValidationError, model_validator\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Initialize logger (if not done globally)\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Any, Callable, Dict, List, Optional\n",
    "\n",
    "class CleanerRegistry:\n",
    "    \"\"\"\n",
    "    A registry for managing and retrieving different types of data cleaners,\n",
    "    categorized into field-level cleaners and model-level cleaners.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the CleanerRegistry with dictionaries to store\n",
    "        cleaners, their required parameters, and any associated metadata.\n",
    "        \"\"\"\n",
    "        # Stores callable functions for field-level cleaners, mapped by their type string.\n",
    "        self._field_cleaners: Dict[str, Callable] = {}\n",
    "        # Stores callable functions for model-level cleaners, mapped by their type string.\n",
    "        self._model_cleaners: Dict[str, Callable] = {}\n",
    "        # Stores lists of required parameter names for each field cleaner type.\n",
    "        self._field_cleaner_params: Dict[str, List[str]] = {}\n",
    "        # Stores lists of required parameter names for each model cleaner type.\n",
    "        self._model_cleaner_params: Dict[str, List[str]] = {}\n",
    "        # Stores additional metadata (e.g., descriptions, default values) for field cleaners.\n",
    "        self._field_cleaner_metadata: Dict[str, Dict[str, Any]] = {}\n",
    "        # Stores additional metadata (e.g., descriptions, default values) for model cleaners.\n",
    "        self._model_cleaner_metadata: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "    def register_field_cleaner(\n",
    "        self,\n",
    "        cleaner_type: str,\n",
    "        cleaner_func: Callable[[str, Dict[str, Any]], Callable],\n",
    "        required_params: List[str] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Registers a field-level cleaner function with a unique type string.\n",
    "\n",
    "        If a cleaner of the same type already exists, it will be overwritten.\n",
    "\n",
    "        Args:\n",
    "            cleaner_type: A unique string identifier for the cleaner.\n",
    "            cleaner_func: The callable function that performs the field cleaning.\n",
    "                          It typically takes a field value and a dictionary of parameters.\n",
    "            required_params: An optional list of parameter names that this cleaner requires.\n",
    "            **kwargs: Additional keyword arguments to store as metadata for the cleaner.\n",
    "        \"\"\"\n",
    "        if cleaner_type in self._field_cleaners:\n",
    "            logging.warning(f\"Field cleaner type '{cleaner_type}' already registered. Overwriting.\")\n",
    "        self._field_cleaners[cleaner_type] = cleaner_func\n",
    "        self._field_cleaner_params[cleaner_type] = required_params or []\n",
    "        self._field_cleaner_metadata[cleaner_type] = kwargs\n",
    "        logging.info(f\"Registered field cleaner: {cleaner_type}\")\n",
    "\n",
    "    def get_field_cleaner(self, cleaner_type: str) -> Optional[Callable]:\n",
    "        \"\"\"\n",
    "        Retrieves a registered field cleaner function by its type.\n",
    "\n",
    "        Args:\n",
    "            cleaner_type: The string identifier of the cleaner to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            The callable field cleaner function if found, otherwise None.\n",
    "        \"\"\"\n",
    "        return self._field_cleaners.get(cleaner_type)\n",
    "\n",
    "    def get_field_params(self, cleaner_type: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieves the list of required parameters for a given field cleaner type.\n",
    "\n",
    "        Args:\n",
    "            cleaner_type: The string identifier of the cleaner.\n",
    "\n",
    "        Returns:\n",
    "            A list of strings representing the required parameter names.\n",
    "            Returns an empty list if the cleaner type is not found.\n",
    "        \"\"\"\n",
    "        return self._field_cleaner_params.get(cleaner_type, [])\n",
    "\n",
    "    def get_field_cleaner_types(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieves a list of all registered field cleaner types.\n",
    "\n",
    "        Returns:\n",
    "            A list of strings, where each string is a registered field cleaner type.\n",
    "        \"\"\"\n",
    "        return list(self._field_cleaners.keys())\n",
    "\n",
    "    def register_model_cleaner(\n",
    "        self,\n",
    "        cleaner_type: str,\n",
    "        cleaner_func: Callable[[List[str], Dict[str, Any]], Callable],\n",
    "        required_params: List[str] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Registers a model-level cleaner function with a unique type string.\n",
    "\n",
    "        If a cleaner of the same type already exists, it will be overwritten.\n",
    "\n",
    "        Args:\n",
    "            cleaner_type: A unique string identifier for the cleaner.\n",
    "            cleaner_func: The callable function that performs the model cleaning.\n",
    "                          It typically takes a list of field values (representing a record/model)\n",
    "                          and a dictionary of parameters.\n",
    "            required_params: An optional list of parameter names that this cleaner requires.\n",
    "            **kwargs: Additional keyword arguments to store as metadata for the cleaner.\n",
    "        \"\"\"\n",
    "        if cleaner_type in self._model_cleaners:\n",
    "            logging.warning(f\"Model cleaner type '{cleaner_type}' already registered. Overwriting.\")\n",
    "        self._model_cleaners[cleaner_type] = cleaner_func\n",
    "        self._model_cleaner_params[cleaner_type] = required_params or []\n",
    "        self._model_cleaner_metadata[cleaner_type] = kwargs\n",
    "        logging.info(f\"Registered model cleaner: {cleaner_type}\")\n",
    "\n",
    "    def get_model_cleaner(self, cleaner_type: str) -> Optional[Callable]:\n",
    "        \"\"\"\n",
    "        Retrieves a registered model cleaner function by its type.\n",
    "\n",
    "        Args:\n",
    "            cleaner_type: The string identifier of the cleaner to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            The callable model cleaner function if found, otherwise None.\n",
    "        \"\"\"\n",
    "        return self._model_cleaners.get(cleaner_type)\n",
    "\n",
    "    def get_model_params(self, cleaner_type: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieves the list of required parameters for a given model cleaner type.\n",
    "\n",
    "        Args:\n",
    "            cleaner_type: The string identifier of the cleaner.\n",
    "\n",
    "        Returns:\n",
    "            A list of strings representing the required parameter names.\n",
    "            Returns an empty list if the cleaner type is not found.\n",
    "        \"\"\"\n",
    "        return self._model_cleaner_params.get(cleaner_type, [])\n",
    "\n",
    "    def get_model_cleaner_types(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieves a list of all registered model cleaner types.\n",
    "\n",
    "        Returns:\n",
    "            A list of strings, where each string is a registered model cleaner type.\n",
    "        \"\"\"\n",
    "        return list(self._model_cleaners.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, List, Optional\n",
    "\n",
    "# Assuming CleanerRegistry is defined in the same module or imported\n",
    "# from .cleaner_registry import CleanerRegistry \n",
    "\n",
    "logger = logging.getLogger(__name__) # Initialize logger for this module\n",
    "\n",
    "class CleanerManager():\n",
    "    \"\"\"\n",
    "    Manages the registration and loading of data cleaner plugins.\n",
    "    It acts as an intermediary, using a CleanerRegistry to store\n",
    "    and retrieve different types of cleaners.\n",
    "    \"\"\"\n",
    "    def __init__(self, registry: 'CleanerRegistry'): \n",
    "        \"\"\"\n",
    "        Initializes the CleanerManager with a reference to a CleanerRegistry.\n",
    "\n",
    "        Args:\n",
    "            registry: An instance of CleanerRegistry to delegate cleaner\n",
    "                      registration and retrieval to.\n",
    "        \"\"\"\n",
    "        self.registry = registry\n",
    "\n",
    "    def register_field_cleaner(\n",
    "        self,\n",
    "        cleaner_type: str,\n",
    "        # cleaner_func is a factory that takes field_name (str) and params (Dict),\n",
    "        # and returns the actual cleaning function (Callable[[Any], Any]).\n",
    "        cleaner_func: Callable[[str, Dict[str, Any]], Callable[[Any], Any]],\n",
    "        required_params: List[str] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Registers a field-level cleaner factory function with the underlying registry.\n",
    "\n",
    "        This method is a wrapper around the registry's method, providing a\n",
    "        consistent interface for cleaner registration.\n",
    "\n",
    "        Args:\n",
    "            cleaner_type: A unique string identifier for the cleaner.\n",
    "            cleaner_func: A factory function that, when called, returns the actual\n",
    "                          cleaning function for a specific field.\n",
    "            required_params: An optional list of parameter names that this cleaner requires.\n",
    "            **kwargs: Additional keyword arguments to store as metadata for the cleaner.\n",
    "        \"\"\"\n",
    "        self.registry.register_field_cleaner(cleaner_type, cleaner_func, required_params, **kwargs)\n",
    "        logger.info(f\"Dynamically registered field cleaner: {cleaner_type}\")\n",
    "\n",
    "    def register_model_cleaner(\n",
    "        self,\n",
    "        cleaner_type: str,\n",
    "        # Signature for model cleaner factory: takes fields (List[str]) and params (Dict),\n",
    "        # and returns the actual model cleaning function (Callable[[List[Dict[str, Any]]], List[Dict[str, Any]]]).\n",
    "        cleaner_func: Callable[[List[str], Dict[str, Any]], Callable[[List[Dict[str, Any]]], List[Dict[str, Any]]]],\n",
    "        required_params: List[str] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Registers a model-level cleaner factory function with the underlying registry.\n",
    "\n",
    "        Similar to field cleaner registration, this method provides a wrapper\n",
    "        for registering model-level cleaners.\n",
    "\n",
    "        Args:\n",
    "            cleaner_type: A unique string identifier for the cleaner.\n",
    "            cleaner_func: A factory function that, when called, returns the actual\n",
    "                          cleaning function for a list of records/models.\n",
    "            required_params: An optional list of parameter names that this cleaner requires.\n",
    "            **kwargs: Additional keyword arguments to store as metadata for the cleaner.\n",
    "        \"\"\"\n",
    "        self.registry.register_model_cleaner(cleaner_type, cleaner_func, required_params, **kwargs)\n",
    "        logger.info(f\"Dynamically registered model cleaner: {cleaner_type}\")\n",
    "\n",
    "    def load_cleaner_plugins(self, config_path: str = \"cleaners.json\") -> None:\n",
    "        \"\"\"\n",
    "        Loads cleaner configurations from a specified JSON file and registers them.\n",
    "\n",
    "        This method reads a JSON file that defines field and model cleaners,\n",
    "        dynamically imports their respective modules and functions, and then\n",
    "        registers them with the CleanerRegistry.\n",
    "\n",
    "        Args:\n",
    "            config_path: The path to the JSON configuration file.\n",
    "                         Defaults to \"cleaners.json\".\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the configuration file is invalid JSON or\n",
    "                        if there are missing required fields in cleaner definitions,\n",
    "                        or if a specified cleaner module/function cannot be loaded.\n",
    "        \"\"\"\n",
    "        config_file = Path(config_path)\n",
    "        if not config_file.exists():\n",
    "            logger.info(f\"Cleaner plugin file not found at {config_path}. Skipping plugin loading.\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            with config_file.open() as f:\n",
    "                config = json.load(f)\n",
    "            logger.info(f\"Loaded cleaner plugins from {config_path}.\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.error(f\"Invalid JSON in plugin file {config_path}: {e}\")\n",
    "            raise ValueError(f\"Invalid JSON in plugin file {config_path}: {e}\")\n",
    "\n",
    "        for cleaner in config.get(\"field_cleaners\", []):\n",
    "            c_type = cleaner.get(\"type\")\n",
    "            module_name = cleaner.get(\"module\")\n",
    "            func_name = cleaner.get(\"function\")\n",
    "            required_params = cleaner.get(\"required_params\", [])\n",
    "            description = cleaner.get(\"description\", \"\")\n",
    "\n",
    "            if not all([c_type, func_name]):\n",
    "                logger.error(f\"Missing required fields in field cleaner configuration: {cleaner}\")\n",
    "                raise ValueError(f\"Missing required fields in field cleaner: {cleaner}\")\n",
    "\n",
    "            try:\n",
    "                # If no module name is provided, assume the function is in the global scope\n",
    "                if not module_name:\n",
    "                    module = globals()\n",
    "                else:\n",
    "                    # Dynamically import the module\n",
    "                    module = __import__(module_name, fromlist=[func_name])\n",
    "\n",
    "                # Get the cleaner function from the imported module\n",
    "                cleaner_func = getattr(module, func_name)\n",
    "                self.registry.register_field_cleaner(\n",
    "                    c_type, cleaner_func, required_params, description=description\n",
    "                )\n",
    "                logger.debug(f\"Successfully loaded field cleaner '{c_type}' from {module_name}.{func_name if module_name else 'global scope'}\")\n",
    "            except (ImportError, AttributeError) as e:\n",
    "                logger.error(f\"Failed to load field cleaner '{c_type}' from {module_name}.{func_name}: {e}\")\n",
    "                raise ValueError(f\"Failed to load field cleaner '{c_type}' from {module_name}.{func_name}: {e}\")\n",
    "\n",
    "        for cleaner in config.get(\"model_cleaners\", []):\n",
    "            c_type = cleaner.get(\"type\")\n",
    "            module_name = cleaner.get(\"module\")\n",
    "            func_name = cleaner.get(\"function\")\n",
    "            required_params = cleaner.get(\"required_params\", [])\n",
    "            description = cleaner.get(\"description\", \"\")\n",
    "\n",
    "            if not all([c_type, func_name]):\n",
    "                logger.error(f\"Missing required fields in model cleaner configuration: {cleaner}\")\n",
    "                raise ValueError(f\"Missing required fields in model cleaner: {cleaner}\")\n",
    "\n",
    "            try:\n",
    "                # If no module name is provided, assume the function is in the global scope\n",
    "                if not module_name:\n",
    "                    module = globals()\n",
    "                else:\n",
    "                    # Dynamically import the module\n",
    "                    module = __import__(module_name, fromlist=[func_name])\n",
    "\n",
    "                # Get the cleaner function from the imported module\n",
    "                cleaner_func = getattr(module, func_name)\n",
    "                self.registry.register_model_cleaner(\n",
    "                    c_type, cleaner_func, required_params, description=description\n",
    "                )\n",
    "                logger.debug(f\"Successfully loaded model cleaner '{c_type}' from {module_name}.{func_name if module_name else 'global scope'}\")\n",
    "            except (ImportError, AttributeError) as e:\n",
    "                logger.error(f\"Failed to load model cleaner '{c_type}' from {module_name}.{func_name}: {e}\")\n",
    "                raise ValueError(f\"Failed to load model cleaner '{c_type}' from {module_name}.{func_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanerConfig(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents the configuration for a single data cleaner.\n",
    "    This model validates the cleaner type and its parameters against a provided registry.\n",
    "    \"\"\"\n",
    "    # The type of cleaner, e.g., \"remove_html_tags\", \"normalize_whitespace\".\n",
    "    type: str\n",
    "    # A dictionary of parameters to be passed to the cleaner function. Defaults to an empty dict.\n",
    "    params: dict = {}\n",
    "\n",
    "    # Private attribute to store the CleanerRegistry instance.\n",
    "    # It's not part of the Pydantic model's data fields and won't be serialized.\n",
    "    _registry: Any = PrivateAttr()\n",
    "\n",
    "    def __init__(self, registry: Any, **data):\n",
    "        \"\"\"\n",
    "        Initializes the CleanerConfig.\n",
    "\n",
    "        Args:\n",
    "            registry: An instance of CleanerRegistry which is used to validate\n",
    "                      the cleaner type and its required parameters.\n",
    "            **data: Arbitrary keyword arguments that match the model's fields (type, params).\n",
    "        \"\"\"\n",
    "        super().__init__(**data)\n",
    "        self._registry = registry\n",
    "        # Immediately validate the cleaner configuration against the registry upon initialization.\n",
    "        self.validate_with_registry()  \n",
    "\n",
    "    def validate_with_registry(self):\n",
    "        \"\"\"\n",
    "        Validates the cleaner's type and parameters against the associated CleanerRegistry.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the cleaner type is not registered or if\n",
    "                        any required parameters are missing.\n",
    "        \"\"\"\n",
    "        # Check if the specified cleaner type is registered in the field cleaner types.\n",
    "        if self.type not in self._registry.get_field_cleaner_types():\n",
    "            raise ValueError(f\"Unknown field cleaner type '{self.type}'\")\n",
    "\n",
    "        # Retrieve the list of required parameters for this cleaner type from the registry.\n",
    "        required_params = self._registry.get_field_params(self.type)\n",
    "        # Identify any required parameters that are missing from the provided 'params' dictionary.\n",
    "        missing = [k for k in required_params if k not in self.params]\n",
    "        if missing:\n",
    "            # If there are missing parameters, raise a ValueError.\n",
    "            raise ValueError(f\"Missing params for cleaner '{self.type}': {missing}\")\n",
    "\n",
    "\n",
    "class FieldCleaningConfig(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents the cleaning configuration for a specific field within a data structure.\n",
    "    It includes the field's name and a list of CleanerConfig instances to apply.\n",
    "    \"\"\"\n",
    "    # The name of the field to which these cleaning operations apply.\n",
    "    name: str\n",
    "    # A list of CleanerConfig instances, specifying the sequence of cleaners to apply to the field.\n",
    "    # Defaults to an empty list, meaning no cleaners are applied by default.\n",
    "    cleaners: List[CleanerConfig] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCleanerConfig(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents the configuration for a single model-level cleaner.\n",
    "    This model validates the cleaner type and its parameters against a provided registry.\n",
    "    \"\"\"\n",
    "    # The type of model cleaner, e.g., \"deduplicate_records\", \"merge_fields\".\n",
    "    type: str\n",
    "    # A list of field names that this model cleaner operates on. Defaults to an empty list.\n",
    "    fields: List[str] = []\n",
    "    # A dictionary of parameters to be passed to the model cleaner function. Defaults to an empty dict.\n",
    "    params: dict = {}\n",
    "\n",
    "    # Private attribute to store the CleanerRegistry instance.\n",
    "    # It's not part of the Pydantic model's data fields and won't be serialized.\n",
    "    _registry: Any = PrivateAttr()\n",
    "\n",
    "    def __init__(self, registry: Any, **data):\n",
    "        \"\"\"\n",
    "        Initializes the ModelCleanerConfig.\n",
    "\n",
    "        Args:\n",
    "            registry: An instance of CleanerRegistry which is used to validate\n",
    "                      the model cleaner type and its required parameters.\n",
    "            **data: Arbitrary keyword arguments that match the model's fields (type, fields, params).\n",
    "        \"\"\"\n",
    "        super().__init__(**data)\n",
    "        self._registry = registry\n",
    "        # Immediately validate the model cleaner configuration against the registry upon initialization.\n",
    "        self.validate_with_registry()\n",
    "\n",
    "    def validate_with_registry(self):\n",
    "        \"\"\"\n",
    "        Validates the model cleaner's type and parameters against the associated CleanerRegistry.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the model cleaner type is not registered or if\n",
    "                        any required parameters are missing.\n",
    "        \"\"\"\n",
    "        # Check if the specified cleaner type is registered in the model cleaner types.\n",
    "        if self.type not in self._registry.get_model_cleaner_types():\n",
    "            raise ValueError(f\"Unknown model cleaner type '{self.type}'\")\n",
    "\n",
    "        # Retrieve the list of required parameters for this model cleaner type from the registry.\n",
    "        required_params = self._registry.get_model_params(self.type)\n",
    "        # Identify any required parameters that are missing from the provided 'params' dictionary.\n",
    "        missing = [k for k in required_params if k not in self.params]\n",
    "        if missing:\n",
    "            # If there are missing parameters, raise a ValueError.\n",
    "            raise ValueError(f\"Missing params for model cleaner '{self.type}': {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchemaCleaningConfig(BaseModel):\n",
    "    schema_name: str\n",
    "    fields: List[FieldCleaningConfig]\n",
    "    model_cleaners: List[ModelCleanerConfig] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from typing import Any, Callable, Dict, List, Optional\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Initialize logger for this module\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- Individual Field Cleaner Functions  ---\n",
    "\n",
    "def create_strip_whitespace_cleaner(field_name: str, params: Dict[str, Any]) -> Callable[[Any], Any]:\n",
    "    \"\"\"\n",
    "    Creates a field cleaner that removes leading and trailing whitespace from string values.\n",
    "\n",
    "    Args:\n",
    "        field_name: The name of the field to which this cleaner will be applied (not directly used in the cleaner itself but helpful for context/logging).\n",
    "        params: A dictionary of parameters for the cleaner (not used for this specific cleaner).\n",
    "\n",
    "    Returns:\n",
    "        A callable function that takes a value and returns the value with whitespace stripped if it's a string.\n",
    "    \"\"\"\n",
    "    def strip_whitespace_cleaner(value: Any) -> Any:\n",
    "        if isinstance(value, str):\n",
    "            return value.strip()\n",
    "        return value\n",
    "    return strip_whitespace_cleaner\n",
    "\n",
    "def create_to_lowercase_cleaner(field_name: str, params: Dict[str, Any]) -> Callable[[Any], Any]:\n",
    "    \"\"\"\n",
    "    Creates a field cleaner that converts string values to lowercase.\n",
    "\n",
    "    Args:\n",
    "        field_name: The name of the field.\n",
    "        params: A dictionary of parameters (not used for this specific cleaner).\n",
    "\n",
    "    Returns:\n",
    "        A callable function that takes a value and returns its lowercase version if it's a string.\n",
    "    \"\"\"\n",
    "    def to_lowercase_cleaner(value: Any) -> Any:\n",
    "        if isinstance(value, str):\n",
    "            return value.lower()\n",
    "        return value\n",
    "    return to_lowercase_cleaner\n",
    "\n",
    "def create_fill_na_cleaner(field_name: str, params: Dict[str, Any]) -> Callable[[Any], Any]:\n",
    "    \"\"\"\n",
    "    Creates a field cleaner that replaces NaN or None values with a specified fill value.\n",
    "\n",
    "    Args:\n",
    "        field_name: The name of the field.\n",
    "        params: A dictionary containing the 'value' to fill NaN/None with.\n",
    "\n",
    "    Returns:\n",
    "        A callable function that takes a value and returns the fill_value if the input is NaN or None.\n",
    "    \"\"\"\n",
    "    # Extract the fill value from parameters; if not provided, it will be None.\n",
    "    fill_value = params.get(\"value\")\n",
    "    def fill_na_cleaner(value: Any) -> Any:\n",
    "        if pd.isna(value) or value is None:\n",
    "            return fill_value\n",
    "        return value\n",
    "    return fill_na_cleaner\n",
    "\n",
    "def create_type_conversion_cleaner(field_name: str, params: Dict[str, Any]) -> Callable[[Any], Any]:\n",
    "    \"\"\"\n",
    "    Creates a field cleaner that attempts to convert values to a specified target type.\n",
    "\n",
    "    Args:\n",
    "        field_name: The name of the field.\n",
    "        params: A dictionary containing 'target_type' (e.g., \"int\", \"float\", \"str\", \"date\").\n",
    "\n",
    "    Returns:\n",
    "        A callable function that attempts to convert the input value to the target type.\n",
    "        Logs a warning and returns the original value if conversion fails.\n",
    "    \"\"\"\n",
    "    # The target type to convert to, must be present in params.\n",
    "    target_type = params[\"target_type\"]\n",
    "    def type_conversion_cleaner(value: Any) -> Any:\n",
    "        try:\n",
    "            if target_type == \"int\":\n",
    "                return int(value)\n",
    "            elif target_type == \"float\":\n",
    "                return float(value)\n",
    "            elif target_type == \"str\":\n",
    "                return str(value)\n",
    "            elif target_type == \"date\":\n",
    "                # Assumes date strings are in ISO format (YYYY-MM-DD)\n",
    "                return date.fromisoformat(str(value))\n",
    "        except (ValueError, TypeError):\n",
    "            logging.warning(f\"Could not convert '{value}' to type '{target_type}' for field '{field_name}'.\")\n",
    "            return value\n",
    "        return value\n",
    "    return type_conversion_cleaner\n",
    "\n",
    "def create_remove_non_numeric_cleaner(field_name: str, params: Dict[str, Any]) -> Callable[[Any], Any]:\n",
    "    \"\"\"\n",
    "    Creates a field cleaner that removes all characters except digits and dots from a string.\n",
    "    Useful for cleaning numeric strings that may contain currency symbols or other non-numeric text.\n",
    "\n",
    "    Args:\n",
    "        field_name: The name of the field.\n",
    "        params: A dictionary of parameters (not used for this specific cleaner).\n",
    "\n",
    "    Returns:\n",
    "        A callable function that takes a value and returns a string with only numeric characters and dots.\n",
    "    \"\"\"\n",
    "    def remove_non_numeric_cleaner(value: Any) -> Any:\n",
    "        if isinstance(value, str):\n",
    "            return re.sub(r'[^0-9.]', '', value)\n",
    "        return value\n",
    "    return remove_non_numeric_cleaner\n",
    "\n",
    "def income_field_cleaner(value):\n",
    "    \"\"\"\n",
    "    A specific cleaner function for 'Income' values, handling 'k' suffix and general string to float conversion.\n",
    "    This function is intended to be used directly or wrapped, not as a factory function in the current registry design.\n",
    "    \"\"\"\n",
    "    if value is None:\n",
    "        return None\n",
    "    if isinstance(value, (int, float)):\n",
    "        return value\n",
    "    if isinstance(value, str):\n",
    "        val = value.strip().lower()\n",
    "        # Regex to match numbers with optional decimal and 'k' suffix\n",
    "        match = re.match(r'^(\\d+(\\.\\d+)?)(k)?$', val)\n",
    "        if match:\n",
    "            num = float(match.group(1))\n",
    "            if match.group(3) == 'k': # If 'k' suffix is present, multiply by 1000\n",
    "                num *= 1000\n",
    "            return num\n",
    "        else:\n",
    "            try:\n",
    "                return float(val) # Attempt direct conversion if regex doesn't match\n",
    "            except ValueError:\n",
    "                logging.warning(f\"Cannot convert Income value '{value}' to float.\")\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "\n",
    "# --- Record-Level Model Cleaner (Applied to a single record/dictionary)  ---\n",
    "\n",
    "def create_inconsistent_data_removal_cleaner(fields: List[str], params: Dict[str, Any]) -> Callable[[Dict[str, Any]], Optional[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Creates a model cleaner that removes an entire record if specific fields\n",
    "    ('Age', 'Income') contain inconsistent or invalid numeric values (e.g., non-positive).\n",
    "\n",
    "    Args:\n",
    "        fields: A list of field names to check for inconsistencies (e.g., [\"Age\", \"Income\"]).\n",
    "        params: A dictionary of parameters (not used for this specific cleaner beyond general context).\n",
    "\n",
    "    Returns:\n",
    "        A callable function that takes a single record (dictionary) and returns\n",
    "        the record if it's consistent, or None if it should be removed.\n",
    "    \"\"\"\n",
    "    def inconsistent_data_removal_cleaner(data: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "        # This cleaner acts on a single record (dictionary) and can return None to indicate removal.\n",
    "        if \"Age\" in data and data[\"Age\"] is not None:\n",
    "            try:\n",
    "                # Check if Age is numeric and less than or equal to zero\n",
    "                if float(data[\"Age\"]) <= 0:\n",
    "                    logging.debug(f\"Removing row due to inconsistent Age: {data.get('Age')}\")\n",
    "                    return None\n",
    "            except (ValueError, TypeError):\n",
    "                # If Age cannot be converted to float, consider it invalid for this check\n",
    "                logging.debug(f\"Invalid Age value for removal check: {data.get('Age')}\")\n",
    "                pass\n",
    "\n",
    "        if \"Income\" in data and data[\"Income\"] is not None:\n",
    "            try:\n",
    "                # Check if Income is numeric and less than or equal to zero\n",
    "                if float(data[\"Income\"]) <= 0:\n",
    "                    logging.debug(f\"Removing row due to inconsistent Income: {data.get('Income')}\")\n",
    "                    return None\n",
    "            except (ValueError, TypeError) as e:\n",
    "                # If Income cannot be converted to float, consider it invalid for this check\n",
    "                logging.debug(f\"Income value invalid for removal check: {data.get('Income')} - {e}\")\n",
    "                pass\n",
    "        return data # If no inconsistency found, return the original data\n",
    "    return inconsistent_data_removal_cleaner\n",
    "\n",
    "\n",
    "# --- Batch Model Cleaner Functions (Applied to a list of records/dictionaries) ---\n",
    "\n",
    "### **Batch Deduplication Cleaner**\n",
    "\n",
    "\n",
    "def create_drop_duplicate_rows_cleaner(fields: List[str], params: Dict[str, Any]) -> Callable[[List[Dict[str, Any]]], List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Creates a cleaner that removes duplicate records from a list of dictionaries.\n",
    "\n",
    "    Args:\n",
    "        fields: A list of keys (column names) to consider when identifying duplicates.\n",
    "                If empty, all keys will be considered.\n",
    "        params: A dictionary that can include a 'keep' strategy (e.g., 'first', 'last', False)\n",
    "                to determine which duplicate to keep. Defaults to 'first'.\n",
    "\n",
    "    Returns:\n",
    "        A callable function that takes a list of dictionaries (records) and returns\n",
    "        a new list with duplicate records removed.\n",
    "    \"\"\"\n",
    "    # Determine the subset of fields to check for duplication. If `fields` is empty, check all columns.\n",
    "    subset_fields = fields if fields else None\n",
    "    # Determine the strategy for keeping duplicates (e.g., 'first' occurrence).\n",
    "    keep_strategy = params.get('keep', 'first')\n",
    "\n",
    "    def batch_deduplication_cleaner(data_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        if not data_list:\n",
    "            return []\n",
    "\n",
    "        # Convert list of dicts to a Pandas DataFrame for efficient duplication handling.\n",
    "        df = pd.DataFrame(data_list)\n",
    "        initial_rows = df.shape[0] # Record initial row count for logging.\n",
    "        # Drop duplicates based on the specified subset of fields and keeping strategy.\n",
    "        df.drop_duplicates(subset=subset_fields, keep=keep_strategy, inplace=True)\n",
    "        final_rows = df.shape[0] # Record final row count.\n",
    "        logger.info(f\"Batch deduplication removed: {initial_rows - final_rows} rows. {final_rows} rows remaining.\")\n",
    "        # Convert the cleaned DataFrame back to a list of dictionaries.\n",
    "        return df.to_dict(orient='records')\n",
    "    return batch_deduplication_cleaner\n",
    "\n",
    "\n",
    "### **Batch Outlier Treatment Cleaner**\n",
    "\n",
    "\n",
    "def create_treat_outliers_cleaner(fields: List[str], params: Dict[str, Any]) -> Callable[[List[Dict[str, Any]]], List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Creates a cleaner that detects and treats outliers in specified numeric fields within a batch of records.\n",
    "\n",
    "    Args:\n",
    "        fields: A list of numeric field names (columns) to apply outlier treatment on.\n",
    "        params: A dictionary that can include:\n",
    "            - 'percentile': The percentile threshold for outlier detection (e.g., 95 for top 5% outliers). Defaults to 95.\n",
    "            - 'random_state': Seed for reproducibility of the Isolation Forest model. Defaults to 42.\n",
    "\n",
    "    Returns:\n",
    "        A callable function that takes a list of dictionaries (records) and returns\n",
    "        a new list with outliers treated based on an auto-selected method (delete, cap, or transform).\n",
    "    \"\"\"\n",
    "    numeric_fields = fields # These are the columns where outlier treatment will be applied.\n",
    "    percentile = params.get('percentile', 95) # Percentile for defining outlier threshold.\n",
    "    random_state = params.get('random_state', 42) # Random state for Isolation Forest.\n",
    "\n",
    "    def batch_outlier_treatment_cleaner(data_list: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        if not data_list:\n",
    "            return []\n",
    "\n",
    "        df = pd.DataFrame(data_list)\n",
    "        cleaned_df = df.copy() # Create a copy to modify\n",
    "\n",
    "        for col in numeric_fields:\n",
    "            # Skip if column doesn't exist or is not numeric.\n",
    "            if col not in cleaned_df.columns or not pd.api.types.is_numeric_dtype(cleaned_df[col]):\n",
    "                logger.warning(f\"Skipping outlier treatment for non-numeric or missing column: {col}\")\n",
    "                continue\n",
    "\n",
    "            # Ensure sufficient data for outlier detection.\n",
    "            if len(cleaned_df[col].dropna()) < 2 or cleaned_df[col].nunique() < 2:\n",
    "                logger.debug(f\"Not enough data or unique values for outlier detection in '{col}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            col_data = cleaned_df[col].dropna() # Isolate non-NaN numeric data for outlier detection.\n",
    "            if col_data.empty:\n",
    "                continue\n",
    "\n",
    "            # Reshape data for IsolationForest (requires 2D array).\n",
    "            X_batch = col_data.values.reshape(-1, 1)\n",
    "\n",
    "            try:\n",
    "                # Initialize and fit Isolation Forest model.\n",
    "                model = IsolationForest(contamination=0.1, random_state=random_state)\n",
    "                model.fit(X_batch)\n",
    "                # Get anomaly scores (lower score indicates more anomalous).\n",
    "                scores = -model.decision_function(X_batch)\n",
    "                # Determine the threshold for outliers based on the specified percentile.\n",
    "                threshold = np.percentile(scores, percentile)\n",
    "                \n",
    "                # Identify indices of outliers from the original DataFrame.\n",
    "                outliers_series = pd.Series(scores >= threshold, index=col_data.index)\n",
    "                outliers = outliers_series[outliers_series].index # Get indices of outliers\n",
    "\n",
    "                outlier_ratio = len(outliers) / len(col_data) # Calculate ratio of outliers.\n",
    "\n",
    "                # Auto-select treatment method based on outlier ratio.\n",
    "                method = \"transform\" # Default method\n",
    "                if outlier_ratio < 0.02:\n",
    "                    method = \"delete\"\n",
    "                elif 0.02 <= outlier_ratio < 0.1:\n",
    "                    method = \"cap\"\n",
    "                else:\n",
    "                    method = \"transform\" # Fallback for higher ratios\n",
    "\n",
    "                logger.info(f\"Auto-selected outlier treatment method for column '{col}': {method} (Outlier ratio: {outlier_ratio:.2f})\")\n",
    "\n",
    "                if method == \"delete\":\n",
    "                    # Remove rows identified as outliers.\n",
    "                    cleaned_df = cleaned_df.drop(outliers)\n",
    "                elif method == \"cap\":\n",
    "                    # Cap outliers to the 5th and 95th percentile of non-outlier data.\n",
    "                    non_outlier_vals = cleaned_df.loc[~cleaned_df.index.isin(outliers), col].dropna()\n",
    "                    if not non_outlier_vals.empty:\n",
    "                        lower_cap = np.percentile(non_outlier_vals, 5)\n",
    "                        upper_cap = np.percentile(non_outlier_vals, 95)\n",
    "                        # Apply capping only to actual outlier values that exceed the caps.\n",
    "                        cleaned_df.loc[cleaned_df.index.isin(outliers) & (cleaned_df[col] < lower_cap), col] = lower_cap\n",
    "                        cleaned_df.loc[cleaned_df.index.isin(outliers) & (cleaned_df[col] > upper_cap), col] = upper_cap\n",
    "                    else:\n",
    "                         logger.warning(f\"Cannot cap column '{col}': no non-outlier values to determine caps.\")\n",
    "                elif method == \"transform\":\n",
    "                    # Apply log1p transformation to reduce the impact of large values.\n",
    "                    # This transformation is applied safely, handling non-numeric or negative values.\n",
    "                    cleaned_df[col] = cleaned_df[col].apply(lambda x: np.log1p(x) if pd.notna(x) and x >= 0 else x)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error during outlier treatment for column '{col}': {e}\", exc_info=True)\n",
    "                continue\n",
    "\n",
    "        return cleaned_df.to_dict(orient='records') # Return the cleaned data as a list of dictionaries.\n",
    "    return batch_outlier_treatment_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 22:23:32,556 - INFO - Registered field cleaner: strip_whitespace\n",
      "2025-06-01 22:23:32,557 - INFO - Dynamically registered field cleaner: strip_whitespace\n",
      "2025-06-01 22:23:32,557 - INFO - Registered field cleaner: to_lowercase\n",
      "2025-06-01 22:23:32,557 - INFO - Dynamically registered field cleaner: to_lowercase\n",
      "2025-06-01 22:23:32,558 - INFO - Registered field cleaner: fill_na\n",
      "2025-06-01 22:23:32,558 - INFO - Dynamically registered field cleaner: fill_na\n",
      "2025-06-01 22:23:32,558 - INFO - Registered field cleaner: type_conversion\n",
      "2025-06-01 22:23:32,558 - INFO - Dynamically registered field cleaner: type_conversion\n",
      "2025-06-01 22:23:32,558 - INFO - Registered field cleaner: remove_non_numeric\n",
      "2025-06-01 22:23:32,559 - INFO - Dynamically registered field cleaner: remove_non_numeric\n",
      "2025-06-01 22:23:32,559 - INFO - Registered model cleaner: drop_duplicates\n",
      "2025-06-01 22:23:32,559 - INFO - Dynamically registered model cleaner: drop_duplicates\n",
      "2025-06-01 22:23:32,560 - INFO - Registered model cleaner: remove_inconsistent\n",
      "2025-06-01 22:23:32,560 - INFO - Dynamically registered model cleaner: remove_inconsistent\n",
      "2025-06-01 22:23:32,560 - INFO - Registered model cleaner: treat_outliers\n",
      "2025-06-01 22:23:32,560 - INFO - Dynamically registered model cleaner: treat_outliers\n"
     ]
    }
   ],
   "source": [
    "# Initialize Cleaner Registry and Manager\n",
    "# An instance of CleanerRegistry is created. This object will be responsible\n",
    "# for storing and managing all the different types of cleaning functions.\n",
    "cleaner_registry = CleanerRegistry()\n",
    "# An instance of CleanerManager is created, passing the cleaner_registry to it.\n",
    "# The manager acts as an interface for registering cleaners and loading them from configurations.\n",
    "cleaner_manager = CleanerManager(cleaner_registry)\n",
    "\n",
    "# Register field cleaners\n",
    "# Each registration includes:\n",
    "# - A unique 'type' string (e.g., \"strip_whitespace\").\n",
    "# - The factory function itself (e.g., `create_strip_whitespace_cleaner`), which, when called\n",
    "#   with field-specific parameters, will produce the actual cleaning function.\n",
    "# - A list of `required_params` that the factory function expects in its `params` dictionary.\n",
    "# - A `description` for better understanding and documentation.\n",
    "cleaner_manager.register_field_cleaner(\"strip_whitespace\", create_strip_whitespace_cleaner, required_params=[], description=\"Strips leading/trailing whitespace\")\n",
    "cleaner_manager.register_field_cleaner(\"to_lowercase\", create_to_lowercase_cleaner, required_params=[], description=\"Converts string to lowercase\")\n",
    "cleaner_manager.register_field_cleaner(\"fill_na\", create_fill_na_cleaner, required_params=[\"value\"], description=\"Fills missing values with a specified value\")\n",
    "cleaner_manager.register_field_cleaner(\"type_conversion\", create_type_conversion_cleaner, required_params=[\"target_type\"], description=\"Converts field to target type\")\n",
    "cleaner_manager.register_field_cleaner(\"remove_non_numeric\", create_remove_non_numeric_cleaner, required_params=[], description=\"Removes non-numeric characters from string\")\n",
    "\n",
    "\n",
    "# Register model cleaners\n",
    "# Similar to field cleaners, these lines register model-level cleaner factory functions.\n",
    "# Model cleaners typically operate on entire records or batches of records.\n",
    "# - \"drop_duplicates\" uses `create_drop_duplicate_rows_cleaner` to handle batch deduplication.\n",
    "# - \"remove_inconsistent\" uses `create_inconsistent_data_removal_cleaner` to remove records\n",
    "#   based on inconsistencies in specific fields.\n",
    "# - \"treat_outliers\" uses `create_treat_outliers_cleaner` for batch outlier detection and treatment.\n",
    "cleaner_manager.register_model_cleaner(\"drop_duplicates\", create_drop_duplicate_rows_cleaner, required_params=[], description=\"Drops duplicate rows from the dataset\")\n",
    "cleaner_manager.register_model_cleaner(\"remove_inconsistent\", create_inconsistent_data_removal_cleaner, required_params=[], description=\"Removes rows with inconsistent data (e.g., age <= 0)\")\n",
    "cleaner_manager.register_model_cleaner(\"treat_outliers\", create_treat_outliers_cleaner, required_params=[\"fields\"], description=\"Treats outliers in specified numeric fields across the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Any, Callable, Dict, List, Optional\n",
    "from pydantic import BaseModel, create_model, ValidationError, model_validator\n",
    "\n",
    "# Assuming these classes are defined and imported from their respective modules:\n",
    "# from .cleaner_registry import CleanerRegistry\n",
    "# from .config_models import SchemaCleaningConfig, FieldCleaningConfig, ModelCleanerConfig\n",
    "\n",
    "logger = logging.getLogger(__name__) # Initialize logger for this module\n",
    "\n",
    "class DynamicCleaner:\n",
    "    \"\"\"\n",
    "    A dynamic data cleaner that applies a series of field-level and model-level\n",
    "    cleaning operations based on a provided `SchemaCleaningConfig`.\n",
    "    It leverages Pydantic for dynamic model creation and validation,\n",
    "    integrating with a CleanerRegistry for cleaner functions.\n",
    "    \"\"\"\n",
    "    def __init__(self, cleaning_config: 'SchemaCleaningConfig', cleaner_registry: 'CleanerRegistry'):\n",
    "        \"\"\"\n",
    "        Initializes the DynamicCleaner.\n",
    "\n",
    "        Args:\n",
    "            cleaning_config: An instance of SchemaCleaningConfig detailing\n",
    "                             the cleaning operations to perform.\n",
    "            cleaner_registry: An instance of CleanerRegistry containing\n",
    "                              all available cleaner factory functions.\n",
    "        \"\"\"\n",
    "        self.cleaning_config = cleaning_config\n",
    "        self.cleaner_registry = cleaner_registry\n",
    "        # Dynamically creates a Pydantic model based on the cleaning configuration.\n",
    "        self.cleaning_model = self._create_cleaning_model()\n",
    "\n",
    "    def _create_cleaning_model(self) -> type:\n",
    "        \"\"\"\n",
    "        Dynamically creates a Pydantic BaseModel that incorporates the specified\n",
    "        field-level and record-level model cleaning logic.\n",
    "\n",
    "        This Pydantic model will have fields corresponding to the schema fields\n",
    "        in `cleaning_config`, and will use a `model_validator(mode='after')`\n",
    "        to apply the cleaning logic.\n",
    "\n",
    "        Returns:\n",
    "            A dynamically created Pydantic BaseModel class configured for cleaning.\n",
    "        \"\"\"\n",
    "        fields = {}\n",
    "        # Define fields for the dynamic Pydantic model.\n",
    "        # Each field from the cleaning_config will be a model field, accepting Any type.\n",
    "        for field_config in self.cleaning_config.fields:\n",
    "            fields[field_config.name] = (Any, ...) # (type, default_value_or_ellipsis_for_required)\n",
    "\n",
    "        # Create a base Pydantic model with the defined fields.\n",
    "        DynamicBaseCleanModel = create_model(self.cleaning_config.schema_name + \"CleanBase\", **fields)\n",
    "\n",
    "        def apply_field_cleaners(cls, values: Dict[str, Any]) -> Dict[str, Any]:\n",
    "            \"\"\"\n",
    "            Applies field-level cleaners to a single record's values.\n",
    "            This function is used within the Pydantic model's validator.\n",
    "            \"\"\"\n",
    "            cleaned_values = values.copy()\n",
    "            for field_config in self.cleaning_config.fields:\n",
    "                field_name = field_config.name\n",
    "                current_value = cleaned_values.get(field_name)\n",
    "                for cleaner_config in field_config.cleaners:\n",
    "                    # Retrieve the cleaner factory from the registry.\n",
    "                    cleaner_func_factory = self.cleaner_registry.get_field_cleaner(cleaner_config.type)\n",
    "                    if cleaner_func_factory:\n",
    "                        # Create the actual cleaning function by calling the factory.\n",
    "                        cleaner_func = cleaner_func_factory(field_name, cleaner_config.params)\n",
    "                        # Apply the cleaner.\n",
    "                        cleaned_value = cleaner_func(current_value)\n",
    "                        logger.debug(f\"Applied field cleaner '{cleaner_config.type}' on '{field_name}'. Original: {current_value}, Cleaned: {cleaned_value}\")\n",
    "                        current_value = cleaned_value # Update value for next cleaner in chain.\n",
    "                cleaned_values[field_name] = current_value # Store the final cleaned value.\n",
    "            return cleaned_values\n",
    "\n",
    "        def apply_record_level_model_cleaners(cls, values: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "            \"\"\"\n",
    "            Applies record-level model cleaners (e.g., those that might remove an entire record).\n",
    "            This function is used within the Pydantic model's validator.\n",
    "            \"\"\"\n",
    "            cleaned_values = values.copy()\n",
    "            for model_cleaner_config in self.cleaning_config.model_cleaners:\n",
    "                # This check assumes 'remove_inconsistent' is designed as a record-level cleaner.\n",
    "                # For more complex scenarios, you might need a metadata flag (e.g., `is_batch_cleaner: False`)\n",
    "                # within `ModelCleanerConfig` or the `CleanerRegistry` to differentiate.\n",
    "                if model_cleaner_config.type == \"remove_inconsistent\": # Example of a record-level model cleaner\n",
    "                    cleaner_func_factory = self.cleaner_registry.get_model_cleaner(model_cleaner_config.type)\n",
    "                    if cleaner_func_factory:\n",
    "                        # Call the factory to get the specific cleaner function for this record.\n",
    "                        cleaner_func = cleaner_func_factory(model_cleaner_config.fields, model_cleaner_config.params)\n",
    "                        # Apply the record-level cleaner.\n",
    "                        cleaned_values = cleaner_func(cleaned_values)\n",
    "                        if cleaned_values is None:\n",
    "                            logger.debug(f\"Record-level model cleaner '{model_cleaner_config.type}' caused row removal.\")\n",
    "                            return None # Indicate this record should be discarded\n",
    "            return cleaned_values\n",
    "\n",
    "        class CustomCleanModel(DynamicBaseCleanModel):\n",
    "            \"\"\"\n",
    "            A Pydantic model that extends the dynamically created base model\n",
    "            and includes a `model_validator` to apply cleaning logic.\n",
    "            \"\"\"\n",
    "            @model_validator(mode='after')\n",
    "            def perform_record_level_cleaning(self) -> Any:\n",
    "                \"\"\"\n",
    "                Pydantic validator that runs after initial model parsing.\n",
    "                It orchestrates the application of field-level and record-level\n",
    "                model cleaners.\n",
    "                \"\"\"\n",
    "                data = self.model_dump() # Get the raw data from the Pydantic instance.\n",
    "                \n",
    "                # Apply all configured field-level cleaners.\n",
    "                cleaned_data = apply_field_cleaners(self.__class__, data)\n",
    "\n",
    "                # Apply record-level model cleaners (e.g., inconsistent data removal).\n",
    "                cleaned_data = apply_record_level_model_cleaners(self.__class__, cleaned_data)\n",
    "                \n",
    "                # If a record-level cleaner returns None, it signals that the record should be removed.\n",
    "                if cleaned_data is None:\n",
    "                    # Raise a specific ValueError to be caught by the `clean_record` method,\n",
    "                    # indicating that the record should be discarded.\n",
    "                    raise ValueError(\"RECORD_TO_BE_REMOVED_BY_CLEANER\")\n",
    "\n",
    "                # Update the Pydantic model instance with the cleaned values.\n",
    "                for key, value in cleaned_data.items():\n",
    "                    setattr(self, key, value)\n",
    "                return self\n",
    "\n",
    "        return CustomCleanModel\n",
    "\n",
    "    def clean_record(self, record: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Cleans a single data record (dictionary) by applying the configured\n",
    "        field-level and record-level model cleaners through the dynamic Pydantic model.\n",
    "\n",
    "        Args:\n",
    "            record: The dictionary representing a single data record.\n",
    "\n",
    "        Returns:\n",
    "            The cleaned record as a dictionary, or None if the record is\n",
    "            marked for removal by a record-level cleaner.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validate the record against the dynamically created Pydantic model.\n",
    "            # This triggers the `perform_record_level_cleaning` validator.\n",
    "            cleaned_instance = self.cleaning_model.model_validate(record)\n",
    "            # Return the cleaned data as a dictionary.\n",
    "            return cleaned_instance.model_dump()\n",
    "        except ValidationError as e:\n",
    "            # Log validation errors, typically for data that doesn't conform to Pydantic's\n",
    "            # type hints after cleaning, though in this dynamic setup, it's less common\n",
    "            # for basic type issues unless explicit type conversions fail badly.\n",
    "            logger.error(f\"Validation error during cleaning for record: {record}. Errors: {e.errors()}\")\n",
    "            return None\n",
    "        except ValueError as e:\n",
    "            # Catch the specific error indicating record removal by a cleaner.\n",
    "            if str(e) == \"RECORD_TO_BE_REMOVED_BY_CLEANER\":\n",
    "                logger.info(f\"Record removed by cleaner: {record}\")\n",
    "                return None\n",
    "            else:\n",
    "                # Re-raise any other unexpected ValueErrors.\n",
    "                raise e\n",
    "\n",
    "    def clean_data(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Cleans a list of data records by applying both record-by-record\n",
    "        cleaning (field and record-level model cleaners) and then\n",
    "        batch-level model cleaners.\n",
    "\n",
    "        Args:\n",
    "            data: A list of dictionaries, where each dictionary is a data record.\n",
    "\n",
    "        Returns:\n",
    "            A list of cleaned data records.\n",
    "        \"\"\"\n",
    "        # Step 1: Apply record-level field and model cleaners to each record individually.\n",
    "        cleaned_records_step1 = []\n",
    "        for i, record in enumerate(data):\n",
    "            cleaned_record = self.clean_record(record)\n",
    "            if cleaned_record is not None: # Only add records that were not marked for removal.\n",
    "                cleaned_records_step1.append(cleaned_record)\n",
    "        \n",
    "        logger.info(f\"After record-level cleaning, {len(cleaned_records_step1)} out of {len(data)} records remain.\")\n",
    "\n",
    "        # Step 2: Apply batch-level model cleaners to the list of records.\n",
    "        final_cleaned_data = cleaned_records_step1 # Start with the data from step 1.\n",
    "        for model_cleaner_config in self.cleaning_config.model_cleaners:\n",
    "            # Identify batch-level model cleaners. This check needs to be robust.\n",
    "            # A cleaner way might be to add a `is_batch_cleaner: bool` flag to ModelCleanerConfig.\n",
    "            if model_cleaner_config.type in [\"drop_duplicates\", \"treat_outliers\"]:\n",
    "                cleaner_func_factory = self.cleaner_registry.get_model_cleaner(model_cleaner_config.type)\n",
    "                if cleaner_func_factory:\n",
    "                    # Get the batch cleaner function (it expects a list of records).\n",
    "                    cleaner_func = cleaner_func_factory(model_cleaner_config.fields, model_cleaner_config.params)\n",
    "                    \n",
    "                    # Apply the batch cleaner.\n",
    "                    initial_count = len(final_cleaned_data)\n",
    "                    final_cleaned_data = cleaner_func(final_cleaned_data)\n",
    "                    logger.info(f\"Applied batch cleaner '{model_cleaner_config.type}'. Records changed from {initial_count} to {len(final_cleaned_data)}.\")\n",
    "\n",
    "        logging.info(f\"Cleaning complete. Final count: {len(final_cleaned_data)} records.\")\n",
    "        return final_cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = [\n",
    "    {\"Name\": \" Alice \", \"Age\": 25, \"Income\": 50000.0, \"Email\": \"ALICE@EXAMPLE.COM\"},\n",
    "    {\"Name\": \"  Bob\", \"Age\": None, \"Income\": 45000.0, \"Email\": \"bob@example.com\"},\n",
    "    {\"Name\": \"David\", \"Age\": 30, \"Income\": None, \"Email\": \"DAVID@EXAMPLE.COM\"},\n",
    "    {\"Name\": \"Eve\", \"Age\": 35, \"Income\": 75000.0, \"Email\": \"EVE@EXAMPLE.COM\"},\n",
    "    {\"Name\": \" Alice \", \"Age\": 25, \"Income\": 50000.0, \"Email\": \"ALICE@EXAMPLE.COM\"}, # Duplicate for testing\n",
    "    {\"Name\": \"Frank\", \"Age\": -5, \"Income\": 80000.0, \"Email\": \"frank@example.com\"}, # Inconsistent age (will be removed)\n",
    "    {\"Name\": \"Grace\", \"Age\": 40, \"Income\": -100.0, \"Email\": \"grace@example.com\"}, # Inconsistent income (will be removed)\n",
    "    {\"Name\": \"Henry\", \"Age\": 50, \"Income\": 10000000.0, \"Email\": \"henry@example.com\"}, # **OUTLIER INCOME**\n",
    "    {\"Name\": \"Jane\", \"Age\": 28, \"Income\": 52000.0, \"Email\": \"jane@example.com\"},\n",
    "    {\"Name\": \"Henry\", \"Age\": 50, \"Income\": 10000000.0, \"Email\": \"henry@example.com\"} # Another duplicate/outlier\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- UPDATED SchemaCleaningConfig to include batch cleaners ---\n",
    "cleaning_schema_config = SchemaCleaningConfig(\n",
    "    schema_name=\"CustomerDataCleaning\",\n",
    "    fields=[\n",
    "        FieldCleaningConfig(\n",
    "            name=\"Name\",\n",
    "            cleaners=[\n",
    "                CleanerConfig(registry=cleaner_registry, type=\"strip_whitespace\", params={}),\n",
    "                CleanerConfig(registry=cleaner_registry, type=\"to_lowercase\", params={})\n",
    "            ]\n",
    "        ),\n",
    "        FieldCleaningConfig(\n",
    "            name=\"Age\",\n",
    "            cleaners=[\n",
    "                CleanerConfig(registry=cleaner_registry, type=\"fill_na\", params={\"value\": 30}),\n",
    "                CleanerConfig(registry=cleaner_registry, type=\"type_conversion\", params={\"target_type\": \"int\"})\n",
    "            ]\n",
    "        ),\n",
    "        FieldCleaningConfig(\n",
    "            name=\"Income\",\n",
    "            cleaners=[\n",
    "                CleanerConfig(registry=cleaner_registry, type=\"remove_non_numeric\", params={}),\n",
    "                CleanerConfig(registry=cleaner_registry, type=\"type_conversion\", params={\"target_type\": \"float\"})\n",
    "            ]\n",
    "        ),\n",
    "        FieldCleaningConfig(\n",
    "            name=\"Email\",\n",
    "            cleaners=[\n",
    "                CleanerConfig(registry=cleaner_registry, type=\"to_lowercase\", params={})\n",
    "            ]\n",
    "        )\n",
    "    ],\n",
    "    model_cleaners=[\n",
    "        ModelCleanerConfig(\n",
    "            registry=cleaner_registry,\n",
    "            type=\"remove_inconsistent\", # Record-level cleaner\n",
    "            fields=[],\n",
    "            params={}\n",
    "        ),\n",
    "        ModelCleanerConfig(\n",
    "            registry=cleaner_registry,\n",
    "            type=\"drop_duplicates\", # Batch-level cleaner\n",
    "            fields=[\"Name\", \"Email\"], # Consider Name and Email for identifying duplicates\n",
    "            params={\"keep\": \"first\"} # Keep the first occurrence\n",
    "        ),\n",
    "        ModelCleanerConfig(\n",
    "            registry=cleaner_registry,\n",
    "            type=\"treat_outliers\",\n",
    "            fields=[], # <-- This `fields` can be an empty list for ModelCleanerConfig\n",
    "            params={\n",
    "                \"fields\": [\"Income\"],\n",
    "                \"percentile\": 99\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 22:23:32,584 - WARNING - Could not convert 'None' to type 'float' for field 'Income'.\n",
      "2025-06-01 22:23:32,585 - ERROR - Validation error during cleaning for record: {'Name': 'Frank', 'Age': -5, 'Income': 80000.0, 'Email': 'frank@example.com'}. Errors: [{'type': 'value_error', 'loc': (), 'msg': 'Value error, RECORD_TO_BE_REMOVED_BY_CLEANER', 'input': {'Name': 'Frank', 'Age': -5, 'Income': 80000.0, 'Email': 'frank@example.com'}, 'ctx': {'error': ValueError('RECORD_TO_BE_REMOVED_BY_CLEANER')}, 'url': 'https://errors.pydantic.dev/2.11/v/value_error'}]\n",
      "2025-06-01 22:23:32,586 - ERROR - Validation error during cleaning for record: {'Name': 'Grace', 'Age': 40, 'Income': -100.0, 'Email': 'grace@example.com'}. Errors: [{'type': 'value_error', 'loc': (), 'msg': 'Value error, RECORD_TO_BE_REMOVED_BY_CLEANER', 'input': {'Name': 'Grace', 'Age': 40, 'Income': -100.0, 'Email': 'grace@example.com'}, 'ctx': {'error': ValueError('RECORD_TO_BE_REMOVED_BY_CLEANER')}, 'url': 'https://errors.pydantic.dev/2.11/v/value_error'}]\n",
      "2025-06-01 22:23:32,587 - INFO - After record-level cleaning, 8 out of 10 records remain.\n",
      "2025-06-01 22:23:32,592 - INFO - Batch deduplication removed: 2 rows. 6 rows remaining.\n",
      "2025-06-01 22:23:32,595 - INFO - Applied batch cleaner 'drop_duplicates'. Records changed from 8 to 6.\n",
      "2025-06-01 22:23:32,597 - INFO - Applied batch cleaner 'treat_outliers'. Records changed from 6 to 6.\n",
      "2025-06-01 22:23:32,598 - INFO - Cleaning complete. Final count: 6 records.\n"
     ]
    }
   ],
   "source": [
    "# --- Execute Cleaning ---\n",
    "dynamic_cleaner = DynamicCleaner(cleaning_schema_config, cleaner_registry)\n",
    "cleaned_data = dynamic_cleaner.clean_data(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Cleaned Data ---\n",
      "{'Name': 'alice', 'Age': 25, 'Income': 50000.0, 'Email': 'alice@example.com'}\n",
      "{'Name': 'bob', 'Age': 30, 'Income': 45000.0, 'Email': 'bob@example.com'}\n",
      "{'Name': 'david', 'Age': 30, 'Income': nan, 'Email': 'david@example.com'}\n",
      "{'Name': 'eve', 'Age': 35, 'Income': 75000.0, 'Email': 'eve@example.com'}\n",
      "{'Name': 'henry', 'Age': 50, 'Income': 10000000.0, 'Email': 'henry@example.com'}\n",
      "{'Name': 'jane', 'Age': 28, 'Income': 52000.0, 'Email': 'jane@example.com'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Final Cleaned Data ---\")\n",
    "for record in cleaned_data:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 22:23:32,608 - ERROR - An unexpected error occurred while loading cleaning schema: ModelCleanerConfig.__init__() missing 1 required positional argument: 'registry'\n",
      "2025-06-01 22:23:32,609 - WARNING - Could not convert 'None' to type 'float' for field 'Income'.\n",
      "2025-06-01 22:23:32,609 - ERROR - Validation error during cleaning for record: {'Name': 'Frank', 'Age': -5, 'Income': 80000.0, 'Email': 'frank@example.com'}. Errors: [{'type': 'value_error', 'loc': (), 'msg': 'Value error, RECORD_TO_BE_REMOVED_BY_CLEANER', 'input': {'Name': 'Frank', 'Age': -5, 'Income': 80000.0, 'Email': 'frank@example.com'}, 'ctx': {'error': ValueError('RECORD_TO_BE_REMOVED_BY_CLEANER')}, 'url': 'https://errors.pydantic.dev/2.11/v/value_error'}]\n",
      "2025-06-01 22:23:32,609 - ERROR - Validation error during cleaning for record: {'Name': 'Grace', 'Age': 40, 'Income': -100.0, 'Email': 'grace@example.com'}. Errors: [{'type': 'value_error', 'loc': (), 'msg': 'Value error, RECORD_TO_BE_REMOVED_BY_CLEANER', 'input': {'Name': 'Grace', 'Age': 40, 'Income': -100.0, 'Email': 'grace@example.com'}, 'ctx': {'error': ValueError('RECORD_TO_BE_REMOVED_BY_CLEANER')}, 'url': 'https://errors.pydantic.dev/2.11/v/value_error'}]\n",
      "2025-06-01 22:23:32,610 - INFO - After record-level cleaning, 8 out of 10 records remain.\n",
      "2025-06-01 22:23:32,610 - INFO - Batch deduplication removed: 2 rows. 6 rows remaining.\n",
      "2025-06-01 22:23:32,611 - INFO - Applied batch cleaner 'drop_duplicates'. Records changed from 8 to 6.\n",
      "2025-06-01 22:23:32,611 - INFO - Applied batch cleaner 'treat_outliers'. Records changed from 6 to 6.\n",
      "2025-06-01 22:23:32,612 - INFO - Cleaning complete. Final count: 6 records.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Cleaned Data ---\n",
      "{'Name': 'alice', 'Age': 25, 'Income': 50000.0, 'Email': 'alice@example.com'}\n",
      "{'Name': 'bob', 'Age': 30, 'Income': 45000.0, 'Email': 'bob@example.com'}\n",
      "{'Name': 'david', 'Age': 30, 'Income': nan, 'Email': 'david@example.com'}\n",
      "{'Name': 'eve', 'Age': 35, 'Income': 75000.0, 'Email': 'eve@example.com'}\n",
      "{'Name': 'henry', 'Age': 50, 'Income': 10000000.0, 'Email': 'henry@example.com'}\n",
      "{'Name': 'jane', 'Age': 28, 'Income': 52000.0, 'Email': 'jane@example.com'}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Load cleaning_schema_config from JSON ---\n",
    "config_path = \"cleaners.json\" # Relative path\n",
    "# If cleaners.json is in a different directory, use:\n",
    "# config_path = \"/path/to/your/configs/cleaners.json\"\n",
    "# or\n",
    "# from pathlib import Path\n",
    "# config_path = Path(__file__).parent / \"configs\" / \"cleaners.json\" # For a 'configs' subfolder\n",
    "\n",
    "try:\n",
    "    with open(config_path, 'r') as f:\n",
    "        config_data = json.load(f)\n",
    "    \n",
    "    # 1. Create the SchemaCleaningConfig from the loaded dictionary\n",
    "    cleaning_schema_config = SchemaCleaningConfig.model_validate(config_data)\n",
    "    \n",
    "    # 2. IMPORTANT: Manually inject the registry into all nested CleanerConfig and ModelCleanerConfig instances\n",
    "    # This is necessary because Pydantic doesn't know about `_registry` during deserialization from JSON.\n",
    "    cleaning_schema_config.set_all_cleaners_registry(cleaner_registry)\n",
    "\n",
    "    logger.info(f\"Successfully loaded cleaning schema from '{config_path}'.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    logger.error(f\"Error: The file '{config_path}' was not found. Please ensure it exists in the correct directory.\")\n",
    "    exit() # Exit if the config file is crucial and missing\n",
    "except json.JSONDecodeError as e:\n",
    "    logger.error(f\"Error decoding JSON from '{config_path}': {e}\")\n",
    "    exit()\n",
    "except ValidationError as e:\n",
    "    logger.error(f\"Validation error when parsing cleaning schema from '{config_path}': {e.errors()}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    logger.error(f\"An unexpected error occurred while loading cleaning schema: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Execute Cleaning ---\n",
    "dynamic_cleaner = DynamicCleaner(cleaning_schema_config, cleaner_registry)\n",
    "cleaned_data = dynamic_cleaner.clean_data(raw_data)\n",
    "\n",
    "print(\"\\n--- Final Cleaned Data ---\")\n",
    "for record in cleaned_data:\n",
    "    print(record)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
